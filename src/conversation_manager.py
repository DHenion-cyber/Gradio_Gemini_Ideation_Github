"""Manages conversation state, user interactions, and integrates with workflows and personas."""
import streamlit as st
import datetime
import uuid
import os
import asyncio
import logging
import random
import re

from persistence_utils import save_session, load_session, ensure_db
from llm_utils import query_openai, generate_contextual_follow_up, build_conversation_messages # Removed unused build_prompt, propose_next_conversation_turn
import search_utils # Changed from 'from src import search_utils'
# Removed: from . import conversation_phases - Phase logic will be handled by workflows
from utils.scratchpad_extractor import update_scratchpad
from constants import EMPTY_SCRATCHPAD, REQUIRED_SCRATCHPAD_KEYS
from registry import get_workflow, get_persona, populate_registries, get_available_workflows, get_available_personas

# Populate the registries when this module is loaded
populate_registries()

def generate_uuid() -> str:
    """Generates a short random string for user_id."""
    return str(uuid.uuid4())[:8] # Using first 8 characters for a short slug

def initialize_conversation_state(new_chat: bool = False):
    # Ensure database and tables are created before any session logic
    try:
        logging.info("DEBUG: Calling ensure_db() from initialize_conversation_state.")
        ensure_db()
        logging.info("DEBUG: ensure_db() call completed in initialize_conversation_state.")
    except Exception as e:
        logging.error(f"CRITICAL: Error calling ensure_db() in initialize_conversation_state: {e}")
        # Optionally, re-raise or handle critical failure, e.g., st.error("Database setup failed!")
        # For now, we'll let it proceed and see if subsequent operations fail,
        # as ensure_db() itself logs critical errors.

    """
    Initializes the conversation state in st.session_state.
    - If `new_chat` is True, it creates a completely fresh session.
    - If `new_chat` is False and `conversation_initialized` is True, it assumes
      the state is already correctly managed by a previous run (e.g., after intake completion)
      and does minimal setup, crucially AVOIDING reloading from disk.
    - If `new_chat` is False and `conversation_initialized` is False (e.g., first ever load,
      or load with a UID in URL), it attempts to load or initialize a new session.
    """
    # This check is now primarily for the very first script run or explicit new chat.
    # For reruns where conversation_initialized is True and new_chat is False,
    # we want to trust the existing st.session_state.

    if new_chat:
        logging.info("DEBUG: initialize_conversation_state called with new_chat=True. Creating fresh session.")
        st.session_state["stage"] = "intake"  # Initial stage
        st.session_state["turn_count"] = 0
        st.session_state["intake_index"] = 0
        st.session_state["scratchpad"] = EMPTY_SCRATCHPAD.copy() # This will be replaced by workflow's scratchpad once initialized
        st.session_state["conversation_history"] = []
        st.session_state["summaries"] = [] # Summaries might be generated by workflows or a general mechanism
        st.session_state["token_usage"] = {"session": 0, "daily": 0}
        st.session_state["last_summary"] = "" # This might be deprecated if summaries are handled differently
        st.session_state["start_timestamp"] = datetime.datetime.now(datetime.timezone.utc)
        st.session_state["user_id"] = generate_uuid()
        st.session_state["maturity_score"] = 0 # This might be persona/workflow specific
        st.session_state["perplexity_calls"] = 0
        st.session_state.setdefault("intake_answers", [])

        # New state for selected workflow and persona
        st.session_state["selected_workflow_name"] = None
        st.session_state["selected_persona_name"] = None
        st.session_state["current_workflow_instance"] = None
        st.session_state["current_persona_instance"] = None
        # st.session_state["phase"] is removed, workflow instance will manage its own current_step or phase

        st.session_state["conversation_initialized"] = True # Mark as initialized
        save_session(st.session_state["user_id"], dict(st.session_state))
        return # Explicitly return after handling new_chat

    # If not a new_chat, check if it's already initialized (e.g., from a previous script run like intake completion)
    if st.session_state.get("conversation_initialized"):
        logging.info("DEBUG: initialize_conversation_state called with new_chat=False, but conversation_initialized is True. Assuming state is managed, doing minimal setup.")
        # Ensure essential keys have defaults if they were somehow missed, but don't overwrite existing session values.
        st.session_state.setdefault("stage", "intake")
        st.session_state.setdefault("turn_count", 0)
        st.session_state.setdefault("intake_index", 0)
        st.session_state.setdefault("user_id", generate_uuid())
        st.session_state.setdefault("scratchpad", EMPTY_SCRATCHPAD.copy())
        st.session_state.setdefault("conversation_history", [])
        st.session_state.setdefault("summaries", [])
        st.session_state.setdefault("token_usage", {"session": 0, "daily": 0})
        st.session_state.setdefault("last_summary", "")
        st.session_state.setdefault("start_timestamp", datetime.datetime.now(datetime.timezone.utc))
        st.session_state.setdefault("maturity_score", 0)
        st.session_state.setdefault("perplexity_calls", 0)
        st.session_state.setdefault("intake_answers", [])

        # New state defaults
        st.session_state.setdefault("selected_workflow_name", None)
        st.session_state.setdefault("selected_persona_name", None)
        st.session_state.setdefault("current_workflow_instance", None)
        st.session_state.setdefault("current_persona_instance", None)
        # st.session_state.setdefault("phase", "exploration") # Phase removed
        return # IMPORTANT: Return here to prevent reloading from disk

    # This part now only runs if new_chat is False AND conversation_initialized is False
    # (i.e., very first load of the app, or first load with a UID in URL)
    logging.info("DEBUG: initialize_conversation_state called with new_chat=False and conversation_initialized is False. Proceeding with load/default init.")
    st.session_state["stage"] = "intake" # Default initial stage
    st.session_state["turn_count"] = 0
    st.session_state["intake_index"] = 0

    query_params = st.query_params
    uid_from_url = query_params.get("uid")

    loaded_successfully = False
    if uid_from_url:
        loaded_data = load_session(uid_from_url)
        if loaded_data:
            st.session_state.update(loaded_data)
            if "user_id" not in st.session_state or not st.session_state["user_id"]:
                st.session_state["user_id"] = uid_from_url
            st.session_state.setdefault("intake_answers", []) # Ensure key exists after loading
            loaded_successfully = True
            logging.info(f"DEBUG: Session loaded for user_id {st.session_state.get('user_id')} from UID {uid_from_url}.")

    if not loaded_successfully:
        # Initialize a new session (either no UID, or UID load failed)
        st.session_state["user_id"] = uid_from_url if uid_from_url else generate_uuid()
        st.session_state.setdefault("scratchpad", EMPTY_SCRATCHPAD.copy())
        st.session_state.setdefault("conversation_history", [])
        st.session_state.setdefault("summaries", [])
        st.session_state.setdefault("token_usage", {"session": 0, "daily": 0})
        st.session_state.setdefault("last_summary", "")
        st.session_state.setdefault("start_timestamp", datetime.datetime.now(datetime.timezone.utc))
        st.session_state.setdefault("maturity_score", 0)
        st.session_state.setdefault("perplexity_calls", 0)
        st.session_state.setdefault("intake_answers", [])

        # New state defaults
        st.session_state.setdefault("selected_workflow_name", None)
        st.session_state.setdefault("selected_persona_name", None)
        st.session_state.setdefault("current_workflow_instance", None)
        st.session_state.setdefault("current_persona_instance", None)
        # st.session_state.setdefault("phase", "exploration") # Phase removed
        logging.info(f"DEBUG: New session initialized for user_id {st.session_state['user_id']}.")

    st.session_state["conversation_initialized"] = True # Mark as initialized
    save_session(st.session_state["user_id"], dict(st.session_state)) # Save whatever state we ended up with

# New function to initialize workflow and persona after user selection
def initialize_workflow_and_persona():
    """
    Initializes the selected workflow and persona instances based on names
    stored in session_state (selected_workflow_name, selected_persona_name).
    This should be called after the user makes their selection in the UI.
    """
    wf_name = st.session_state.get("selected_workflow_name")
    p_name = st.session_state.get("selected_persona_name")

    if not wf_name or not p_name:
        st.error("Workflow or Persona not selected. Please make a selection to continue.")
        logging.error("Attempted to initialize workflow/persona without selection.")
        return False

    PersonaClass = get_persona(p_name)
    WorkflowClass = get_workflow(wf_name)

    if not PersonaClass or not WorkflowClass:
        st.error(f"Invalid workflow ('{wf_name}') or persona ('{p_name}') selection. Available workflows: {get_available_workflows()}, Available personas: {get_available_personas()}")
        logging.error(f"Invalid workflow/persona class for names: {wf_name}, {p_name}")
        return False

    try:
        # TODO: Ensure PersonaClass __init__ is compatible (e.g., no args or takes context)
        persona_instance = PersonaClass()
        st.session_state["current_persona_instance"] = persona_instance

        # TODO: Ensure WorkflowClass __init__ takes (persona_instance, context=None)
        # This requires changes to all workflow classes.
        workflow_instance = WorkflowClass(persona_instance=persona_instance)
        st.session_state["current_workflow_instance"] = workflow_instance
        
        # The workflow instance now holds its own scratchpad.
        # Update the central scratchpad reference.
        st.session_state["scratchpad"] = workflow_instance.scratchpad

        st.session_state["stage"] = "workflow_active" # Transition to active workflow stage
        logging.info(f"Successfully initialized workflow '{wf_name}' with persona '{p_name}'.")
        save_session(st.session_state["user_id"], dict(st.session_state))
        return True
    except Exception as e:
        st.error(f"Error initializing workflow/persona: {e}")
        logging.error(f"Exception during workflow/persona instantiation for {wf_name}/{p_name}: {e}", exc_info=True)
        st.session_state["current_workflow_instance"] = None
        st.session_state["current_persona_instance"] = None
        return False

def get_intake_questions() -> list[str]:
    """
    Returns the list of intake questions.
    """
    return [
        "Hello! I'm digital health innovation agent! I'll start by asking you a series of intake questions to get to know you.\n\nPlease describe any experience or familiarity you have within the health landscape. This may come from positions on your resume, training you've recieved, or experiences you've had.",
        "What specific areas of digital health are you most interested in? (e.g., telemedicine, wearable tech, AI in diagnostics, etc.)",
        "Are there problems that you're particularly interested in addressing?",
        "Some people naturally focus on patient impact, where others naturally focus more on processes, efficiency, finances, etc. Do you find yourself naturally oriented towards one of the following areas?\n- Patient Impact\n- Quality (may not be directly patients)\n- Finance/savings\n- Efficiency\n- New Technology",
        "Do you already have some ideas or topics you want to explore?",
        "Are there any potential business qualities that matter to you? For example, some people are interested in smaller scale innovations that could be launched quickly with minimum funding while others may be more interested in exploring big ideas with longer timelines and external funding."
    ]

def run_intake_flow(user_input: str):
    """
    Processes user input for the intake flow and advances the intake_index.
    This function should be called *only* when user_input is provided.
    """
    intake_questions = get_intake_questions()

    # Store user's intake response in st.session_state["intake_answers"]
    # and not in st.session_state["conversation_history"]
    st.session_state.setdefault("intake_answers", [])
    st.session_state["intake_answers"].append({
        "role": "user",
        "text": user_input,
        "timestamp": datetime.datetime.now(datetime.timezone.utc).isoformat(),
        "meta": "intake" # Mark message as intake-related
    })

    # Store intake answers in scratchpad where relevant
    # intake_index is incremented *after* processing, so current_intake_index refers to the question just answered
    current_intake_index = st.session_state["intake_index"]
    if current_intake_index == 0: # First question about expertise/interests
        # This is a general introductory question, no direct scratchpad mapping needed yet.
        pass
    elif current_intake_index == 1: # Problems interested in
        st.session_state["scratchpad"]["problem"] = user_input
    elif current_intake_index == 2: # Areas of orientation (Patient Impact, Quality, etc.)
        st.session_state["scratchpad"]["solution"] = user_input # Mapped to canonical 'solution'
    elif current_intake_index == 3: # Existing ideas or brainstorming
        # This can inform solution or other canonical keys.
        # For now, we'll keep it as pass, as it's more about intent.
        pass
    elif current_intake_index == 4: # Business qualities
        # st.session_state["scratchpad"]["revenue_model"] = user_input # Removed: 'revenue_model' is not a required scratchpad key.
        pass # This information can be captured in conversation_history if needed, but not in the core scratchpad.

    st.session_state["intake_index"] += 1

    if st.session_state["intake_index"] >= len(intake_questions):
        # Stage transition will be handled by streamlit_app.py
        logging.info("Intake complete based on intake_index. Stage transition will be handled by UI.")
        
        answers_texts = [
            ans.get("text", "")
            for ans in st.session_state.get("intake_answers", [])
            if isinstance(ans, dict)
        ]
        intake_summary = "Summary of your background and interests: " + " ".join(answers_texts)
        st.session_state["context_summary"] = intake_summary
        
        # Compute and store best_answer from intake_answers for the transition
        # Ensure answers_texts is not empty for max() to prevent error, default to empty string
        if not answers_texts: # This check should use the original answers_texts
            answers_texts_for_max = [""] # Use a different variable if answers_texts was modified for summary
        else:
            answers_texts_for_max = answers_texts
        st.session_state["best_intake_answer_for_transition"] = max(answers_texts_for_max, key=len, default="")

    save_session(st.session_state["user_id"], st.session_state.to_dict())

async def generate_assistant_response(user_input: str) -> tuple[str, list]:
    """
    Generates an assistant response using the LLM, builds the prompt,
    queries Gemini, and stores the result in conversation history.
    Returns the response text and the search results.
    """
    # This patch is to support simulation/test scripts that run without `streamlit run` or UI context.
    # Initialize essential session state keys if they don't exist, providing defaults for simulation.
    st.session_state.setdefault("conversation_history", [])
    st.session_state.setdefault("user_id", generate_uuid()) # Ensure user_id exists
    st.session_state.setdefault("scratchpad", EMPTY_SCRATCHPAD.copy())
    st.session_state.setdefault("summaries", [])
    st.session_state.setdefault("token_usage", {"session": 0, "daily": 0})
    st.session_state.setdefault("last_summary", "")
    st.session_state.setdefault("start_timestamp", datetime.datetime.now(datetime.timezone.utc))
    st.session_state.setdefault("maturity_score", 0)
    st.session_state.setdefault("perplexity_calls", 0)
    # st.session_state.setdefault("phase", "exploration") # Phase removed
    st.session_state.setdefault("module", "default_module") # Default module for simulation
    st.session_state.setdefault("turn_count", 0) # Ensure turn_count exists

    logging.debug(f"generate_assistant_response called with user_input: '{user_input[:50]}...'")

    workflow_instance = st.session_state.get("current_workflow_instance")
    if not workflow_instance:
        logging.error("generate_assistant_response: No active workflow instance found.")
        # This case should ideally be handled by UI flow (e.g., prompting for workflow selection)
        # or if called programmatically, ensure initialize_workflow_and_persona was successful.
        return "No active workflow. Please select a workflow and persona to continue.", []

    search_results = []
    perform_web_search = False
    user_input_lower = user_input.lower()
    # Keywords that might trigger a web search if the persona/workflow decides it's necessary.
    # This logic might be better placed within the persona.
    search_keywords = ["search for", "research", "find information on", "look up", "what is", "who is", "tell me about"]

    if any(keyword in user_input_lower for keyword in search_keywords):
        perform_web_search = True
        logging.debug("User input suggests a web search.")
    
    # TODO: Consider if phase-specific search logic (like old 'refinement' phase) is needed,
    # or if the active workflow/persona should determine search needs.
    # For now, keeping explicit search trigger.

    if perform_web_search:
        current_calls = st.session_state.get("perplexity_calls", 0)
        if current_calls < search_utils.MAX_PERPLEXITY_CALLS:
            perplexity_api_key = os.environ.get("PERPLEXITY_API_KEY")
            if perplexity_api_key:
                st.session_state["perplexity_calls"] = current_calls + 1
                logging.info(f"Performing Perplexity search for: {user_input}. Call count: {st.session_state['perplexity_calls']}")
                try:
                    search_results = await search_utils.perform_search(user_input)
                except Exception as e:
                    logging.error(f"Error during Perplexity search: {e}", exc_info=True)
                    search_results = [{"error": "Search failed."}] # Pass error info
            else:
                logging.warning("PERPLEXITY_API_KEY not set. Skipping search.")
                search_results = [{"info": "Search skipped, API key missing."}]
        else:
            logging.info(f"Perplexity call cap reached ({current_calls}). Skipping search.")
            search_results = [{"info": "Search skipped, call cap reached."}]

    # Delegate response generation to the workflow instance.
    # The workflow's process_user_input method will use its persona.
    # TODO: Ensure all workflow process_user_input methods accept (user_input, search_results=None)
    # and that personas can utilize search_results.
    try:
        # Assuming workflow.process_user_input is synchronous for now.
        # If persona methods become async, this will need to be awaited.
        final_response_text = workflow_instance.process_user_input(user_input, search_results=search_results)
        
        # Sync scratchpad from workflow instance to central session state scratchpad
        if hasattr(workflow_instance, 'scratchpad'):
            st.session_state["scratchpad"] = workflow_instance.scratchpad
        else:
            logging.warning(f"Workflow instance of type {type(workflow_instance)} does not have a 'scratchpad' attribute.")


        if workflow_instance.is_complete():
            # Optionally, generate a final summary from the workflow
            # final_summary = workflow_instance.generate_summary()
            # final_response_text += f"\n\n**Workflow Complete: Summary**\n{final_summary}"
            st.session_state["stage"] = "workflow_completed" # Or some other terminal stage
            logging.info(f"Workflow {st.session_state.get('selected_workflow_name')} completed.")
            # The UI can then display options for a new workflow or ending the session.

    except Exception as e:
        logging.error(f"Error in workflow.process_user_input: {e}", exc_info=True)
        final_response_text = "An error occurred while processing your request with the workflow."


    st.session_state["conversation_history"].append({
        "role": "assistant",
        "text": final_response_text,
        "timestamp": datetime.datetime.now(datetime.timezone.utc).isoformat()
    })
    st.session_state["turn_count"] += 1
    save_session(st.session_state["user_id"], dict(st.session_state))
    return final_response_text, search_results

# Removed route_conversation function as its logic is now incorporated into
# generate_assistant_response and handled by workflow instances.

def generate_actionable_recommendations(element: str, context: str):
    """
    Generates up to 2 research-based suggestions for a given element and context,
    and appends them to conversation_history as assistant turns.
    """
    # In a real implementation, this would query an LLM or a knowledge base
    # to generate relevant recommendations based on the element and context.
    # For testing, we'll assume query_openai returns a string like "1. Rec1\n2. Rec2"
    mock_response = query_openai(f"Generate recommendations for {element} based on {context}")
    # Ensure that the mock response is split into at least two recommendations for the test
    recommendations = [rec.strip() for rec in mock_response.split('\n') if rec.strip()]
    if len(recommendations) < 2:
        # Add dummy recommendations if the mock response doesn't provide enough
        recommendations.extend([f"Additional Recommendation {i}" for i in range(2 - len(recommendations))])

    for rec in recommendations:
        st.session_state["conversation_history"].append({
            "role": "assistant",
            "text": rec,
            "timestamp": datetime.datetime.now(datetime.timezone.utc).isoformat()
        })
    save_session(st.session_state["user_id"], st.session_state.to_dict())
    return recommendations # Return the list of recommendations

def trim_conversation_history():
    """
    Trims the conversation history based on the number of summaries or token count.
    Removes oldest 5 turns already covered by summaries if conditions are met.
    """
    # Placeholder for actual token counting logic
    # For now, we'll use a simple approximation or assume a function exists.
    def count_tokens(text: str) -> int:
        return len(text.split()) # Simple word count as token approximation

    current_history_tokens = sum(count_tokens(turn["text"]) for turn in st.session_state["conversation_history"])

    if len(st.session_state["summaries"]) >= 20 or current_history_tokens >= 4000:
        # Determine how many turns to remove. This logic needs to be careful
        # not to remove turns that are not yet summarized.
        # For simplicity, we'll just remove the oldest 5 if the condition is met.
        # A more robust solution would track which turns are covered by which summaries.
        if len(st.session_state["conversation_history"]) > 5:
            st.session_state["conversation_history"] = st.session_state["conversation_history"][5:]
            st.session_state["summaries"] = st.session_state["summaries"][1:] # Remove oldest summary if it covers these turns
            save_session(st.session_state["user_id"], st.session_state.to_dict())

def create_turn_summary(text: str) -> str:
    """
    Sends text to Gemini to create a short (<=100-token) summary,
    stores it in last_summary, and appends to summaries.
    """
    # In a real implementation, this would query Gemini for a summary.
    # For now, a simple truncation.
    summary = f"Summary of: {text[:150]}..." # Truncate for demo
    if len(summary.split()) > 100:
        summary = " ".join(summary.split()[:100]) + "..."

    st.session_state["last_summary"] = summary
    st.session_state["summaries"].append(summary)
    save_session(st.session_state["user_id"], st.session_state.to_dict())
    return summary

def reconstruct_context_from_summaries() -> str:
    """
    Combines the latest 10 summaries and the 3 most recent conversation turns
    to reconstruct context for LLM prompt building.
    """
    context_parts = []

    # Add latest 10 summaries
    context_parts.extend(st.session_state["summaries"][-10:])

    # Add 3 most recent conversation turns
    recent_turns = st.session_state["conversation_history"][-3:]
    for turn in recent_turns:
        context_parts.append(f"{turn['role']}: {turn['text']}")

    return "\n".join(context_parts)

def build_summary_from_scratchpad(scratchpad: dict) -> str:
    """
    Returns the full summary from current scratchpad content for export or simulation logs.
    Reflects the new scratchpad structure.
    """
    summary_report = []
    # Iterate over REQUIRED_SCRATCHPAD_KEYS to ensure all required keys are checked
    # and to maintain a consistent order, similar to how EMPTY_SCRATCHPAD is defined.
    for key in REQUIRED_SCRATCHPAD_KEYS:
        value = scratchpad.get(key)
        if key == "research_requests":
            if value and isinstance(value, list):
                # Format research requests for the log
                formatted_requests = []
                for item in value:
                    if isinstance(item, dict):
                        formatted_requests.append(f"- Step: {item.get('step', 'N/A')}, Details: {item.get('details', 'N/A')}")
                    else:
                        formatted_requests.append(f"- {str(item)}")
                summary_report.append(f"\n{key.replace('_', ' ').title()}:\n" + "\n".join(formatted_requests) if formatted_requests else f"\n{key.replace('_', ' ').title()}:\nN/A")
            else:
                summary_report.append(f"\n{key.replace('_', ' ').title()}:\nN/A")
        elif value:
            summary_report.append(f"\n{key.replace('_', ' ').title()}:\n{value}")
        else:
            summary_report.append(f"\n{key.replace('_', ' ').title()}:\nN/A")

    return "\n".join(summary_report).strip()


def generate_final_summary_report() -> str:
    """
    Generates a final summary report for export or display.
    """
    scratchpad = st.session_state.get("scratchpad", {})
    return build_summary_from_scratchpad(scratchpad)

def is_out_of_scope(msg: str) -> bool:
    """
    Determines if a message is out of scope for the assistant.
    """
    out_of_scope_keywords = [
        "order", "book", "schedule", "reserve", "payment", "purchase",
        "shipping", "refund", "cancel", "return", "exchange", "track"
    ]
    msg_lower = msg.lower()
    return any(keyword in msg_lower for keyword in out_of_scope_keywords)

def update_token_usage(tokens: int):
    """
    Updates the token usage tracking in session state.
    """
    try:
        st.session_state.setdefault("token_usage", {"session": 0, "daily": 0})
        st.session_state["token_usage"]["session"] += tokens
        st.session_state["token_usage"]["daily"] += tokens
        save_session(st.session_state["user_id"], st.session_state.to_dict())
    except Exception as e:
        logging.error(f"Error updating token usage: {e}")

def enforce_session_time():
    """
    Enforces a maximum session time of 2 hours.
    """
    if st.session_state.get("start_timestamp"):
        session_duration = datetime.datetime.now(datetime.timezone.utc) - st.session_state["start_timestamp"]
        if session_duration > datetime.timedelta(hours=2):
            st.error("Session has expired due to inactivity. Please start a new chat.")
            st.stop()